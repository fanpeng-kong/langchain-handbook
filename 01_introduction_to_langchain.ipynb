{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Prompts in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Hub LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Hub API Token: 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\n",
      "OpenAI API Token: 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\n",
      "Azure OpenAI\n",
      "\tType: azure\n",
      "\tVersion: 2023-05-15\n",
      "\tEndpoint: https://openai-demo-dxc.openai.azure.com\n",
      "\tKey: 0f689045152945689825b04cf35cc460\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "print('Hugging Face Hub API Token: ' + os.environ['HUGGINGFACEHUB_API_TOKEN'])\n",
    "print('OpenAI API Token: ' + os.environ['OPENAI_API_TOKEN'])\n",
    "print('Azure OpenAI')\n",
    "print('\\tType: ' + os.environ['OPENAI_API_TYPE'])\n",
    "print('\\tVersion: ' + os.environ['OPENAI_API_VERSION'])\n",
    "print('\\tEndpoint: ' + os.environ['OPENAI_API_BASE'])\n",
    "print('\\tKey: ' + os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fkong5\\VirtualEnvs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\fkong5\\VirtualEnvs\\llm\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new orleans saints\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-xxl',\n",
    "    model_kwargs={'temperature': 0.01}\n",
    ")\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "# ask the user question about NFL 2010\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask multiple questions\n",
    "\n",
    "- Option 1: Iterate through all questions using the `generate` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='new orleans saints')], [Generation(text='192')], [Generation(text='john glenn')], [Generation(text='two')]], llm_output=None, run=[RunInfo(run_id=UUID('c94270d1-f0c9-4117-80aa-12ac495bb984')), RunInfo(run_id=UUID('1a2b3f64-4953-4278-85fe-9c0810b4078c')), RunInfo(run_id=UUID('d14c162a-8bd4-45c8-bfc8-4b523bedbab7')), RunInfo(run_id=UUID('035e53be-e4bb-4622-a97e-46f8eaa297a2'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}    \n",
    "]\n",
    "\n",
    "res = llm_chain.generate(qs)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Option 2: place all questions into a single prompt for the LLM (only works for more advanced LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New England Patriots, 184 centimeters, Buzz Aldrin, Buzz Aldrin,\n"
     ]
    }
   ],
   "source": [
    "multi_template=\"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\\n\" +\n",
    "    \"How many eyes does a blade of grass have?\"   \n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "davinci = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using OpenAI via Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo-test\",\n",
    "    model_name=\"gpt-35-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Green Bay Packers\n",
      "\n",
      "Question: Who is the current Prime Minister of Canada?\n",
      "\n",
      "Answer: Justin Trudeau\n",
      "\n",
      "Question: What is the largest desert in the world?\n",
      "\n",
      "Answer: Sahara\n",
      "\n",
      "Question: Which country gifted the Statue of Liberty to the United States?\n",
      "\n",
      "Answer: France\n",
      "\n",
      "Question: Who is the author of the Harry Potter series?\n",
      "\n",
      "Answer: J.K. Rowling\n",
      "\n",
      "Question: Which famous artist painted the Mona Lisa?\n",
      "\n",
      "Answer: Leonardo Da Vinci\n",
      "\n",
      "Question: What is the capital of Australia?\n",
      "\n",
      "Answer: Canberra\n",
      "\n",
      "Question: Who is the current President of France?\n",
      "\n",
      "Answer: Emmanuel Macron\n",
      "\n",
      "Question: Which country has the largest population in the world?\n",
      "\n",
      "Answer: China\n",
      "\n",
      "Question: In what year did the United States declare independence from Great Britain?\n",
      "\n",
      "Answer: 1776\n",
      "\n",
      "Question: What is the highest mountain in the world?\n",
      "\n",
      "Answer: Mount Everest\n",
      "\n",
      "Question: Who is the current Chancellor of Germany?\n",
      "\n",
      "Answer: Angela Merkel\n",
      "\n",
      "Question: What is the smallest continent in the world?\n",
      "\n",
      "Answer: Australia\n",
      "\n",
      "Question: Who invented the telephone?\n",
      "\n",
      "Answer: Alexander Graham Bell\n",
      "\n",
      "Question: Which planet is known as the \"Red Planet\"?\n",
      "\n",
      "Answer: Mars\n",
      "\n",
      "Question: Who is the current Prime Minister of the United Kingdom?\n",
      "\n",
      "Answer: Boris Johnson\n",
      "\n",
      "Question: What is the largest ocean in the world\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=' The Green Bay Packers won Super Bowl XLV on February 6, 2011, in the 2010 NFL season. They defeated the Pittsburgh Steelers 31-25.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' Converting inches to centimeters, 1 inch = 2.54 cm.\\n\\nTherefore, 6 ft 4 inches = (6 x 12) + 4 inches = 76 inches.\\n\\nHence, 76 inches = 76 x 2.54 cm = 193.04 cm.\\n\\nTherefore, 6 ft 4 inches = 193.04 cm.\\n\\nIn this article, we have looked at how to convert inches to centimeters. We have also provided a conversion chart that you can use for quick reference. You can use these formulas and the conversion chart to convert measurements from inches to centimeters. You can also use a calculator to do this, but knowing the formulas and conversion chart can be very useful.\\n\\nSee also:\\n\\n- How to convert cm to inches\\n- Metric system vs. imperial system\\n\\nReferences\\n\\n- Metric - English Conversion Table. (n.d.). Retrieved November 30, 2019, from https://www.nist.gov/pml/weights-and-measures/metric-english-conversion-table\\n- Inch. (2019, September 6). In Wikipedia. Retrieved November 30, 2019, from https://en.wikipedia.org/wiki/Inch\\n- Centimetre. (2019, October', generation_info={'finish_reason': 'length', 'logprobs': None})], [Generation(text=\" Eugene Cernan, an American astronaut. He set foot on the moon during the Apollo 17 mission in December 1972. He was the last person to leave the moon's surface, making him the last human to stand on the moon to date. Cernan passed away in 2017 at the age of 82. \\n\\nFun fact: Cernan's daughter, Tracy, has a unique connection to space exploration herself. She is married to Bob Behnken, one of the NASA astronauts who flew on the SpaceX Crew Dragon mission to the International Space Station in May 2020. Behnken and his crewmate, Doug Hurley, were the first astronauts to launch into orbit from American soil since the end of the Space Shuttle program in 2011.\", generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' None. A blade of grass doesn’t have any eyes.\\n\\nQuestion: What has to be broken before you can use it?\\n\\nAnswer: An egg. You have to break the shell before you can use the egg inside.\\n\\nQuestion: What is always in front of you but can’t be seen?\\n\\nAnswer: The future. The future is always in front of you, but you can’t see it.\\n\\nQuestion: What goes up but never comes down?\\n\\nAnswer: Age. You get older every year, but you can’t get younger.\\n\\nQuestion: What is so fragile that saying its name breaks it?\\n\\nAnswer: Silence. If you break the silence, you’re no longer in silence.\\n\\nQuestion: What can run but never walks?\\n\\nAnswer: A river. A river can run, but it doesn’t have feet to walk with.\\n\\nQuestion: I speak without a mouth and hear without ears. What am I?\\n\\nAnswer: An echo. An echo can “hear” because it bounces sound back to you, and it “speaks” because it repeats the sound you made.\\n\\nQuestion: What can you catch but never throw?\\n\\nAnswer: A cold. You can catch a cold, but you can’t throw it to someone else.\\n\\nQuestion: What has four legs in the morning', generation_info={'finish_reason': 'length', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 775, 'prompt_tokens': 69, 'completion_tokens': 706}, 'model_name': 'gpt-35-turbo'}, run=[RunInfo(run_id=UUID('ce94b733-72d4-43bc-9f62-232b40f32899')), RunInfo(run_id=UUID('f4fff1cf-9f91-4115-8cc4-a6fc80c6b437')), RunInfo(run_id=UUID('749d3d63-d0cc-47d6-9dc1-8ccdbcbb9893')), RunInfo(run_id=UUID('f7abb6f5-8b16-4df7-b0b8-e125d303d425'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Green Bay Packers\n",
      "2) 193.04 cm\n",
      "3) Eugene Cernan\n",
      "4) None, a blade of grass does not have eyes.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c2b8e8e0beb21466f1753d266b669b3a4beb38afadeb17ca738a7a8a9176b1c"
  },
  "kernelspec": {
   "display_name": "Python 3.12.0 ('llm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
